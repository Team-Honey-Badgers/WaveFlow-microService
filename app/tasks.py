"""
Celery íƒœìŠ¤í¬ ì •ì˜ ëª¨ë“ˆ
ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¹„ë™ê¸° ì‘ì—…ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤.
ìƒˆë¡œìš´ ì›Œí¬í”Œë¡œìš°: í•´ì‹œ ìƒì„± -> ì›¹í›… -> ì¤‘ë³µ ê²€ì‚¬ ê²°ê³¼ì— ë”°ë¥¸ ë¶„ê¸° ì²˜ë¦¬
"""

import os
import logging
import tempfile
import uuid
import hashlib
from celery import current_task
from celery.exceptions import Retry
from .celery_app import celery_app
from .audio_processor import AudioProcessor
from .aws_utils import aws_utils

logger = logging.getLogger(__name__)

@celery_app.task(name='app.tasks.generate_hash_and_webhook', bind=True)
def generate_hash_and_webhook(self, userId: str = None, trackId: str = None, 
                             stemId: str = None, filepath: str = None, 
                             timestamp: str = None, original_filename: str = None,
                             sessionId: str = None, file_name: str = None,
                             key: str = None, tag: str = None, 
                             description: str = None, category_id: str = None):
    """
    1ë‹¨ê³„: í•´ì‹œ ìƒì„± ë° ì›¹í›… ì „ì†¡ í…ŒìŠ¤í¬
    S3ì—ì„œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ í•´ì‹œë¥¼ ìƒì„±í•˜ê³ , ì›¹í›…ìœ¼ë¡œ NestJS ì„œë²„ì— ì „ì†¡
    NestJSì—ì„œ ì¤‘ë³µ ê²€ì‚¬ í›„ ì¤‘ë³µì´ ì•„ë‹ˆë©´ DB ë ˆì½”ë“œ ìƒì„±
    
    Args:
        userId: ì‚¬ìš©ì ID
        trackId: íŠ¸ë™ ID
        stemId: ì„ì‹œ ìŠ¤í…œ ID (DB ë ˆì½”ë“œ ìƒì„± í›„ ì‹¤ì œ IDë¡œ ë³€ê²½ë¨)
        filepath: S3 íŒŒì¼ ê²½ë¡œ
        timestamp: íƒ€ì„ìŠ¤íƒ¬í”„
        original_filename: ì›ë³¸ íŒŒì¼ëª…
        sessionId: ì„¸ì…˜ ID
        file_name: íŒŒì¼ëª…
        key: ì‚¬ìš©ì ì…ë ¥ í‚¤
        tag: ì‚¬ìš©ì ì…ë ¥ íƒœê·¸
        description: ì‚¬ìš©ì ì…ë ¥ ì„¤ëª…
        category_id: ì¹´í…Œê³ ë¦¬ ID
        
    Returns:
        dict: ì²˜ë¦¬ ê²°ê³¼ (í•´ì‹œê°’ í¬í•¨)
    """
    task_id = self.request.id
    local_filepath = None
    
    logger.info("====== í•´ì‹œ ìƒì„± ë° ì›¹í›… ì „ì†¡ í…ŒìŠ¤í¬ ì‹œì‘ ======")
    logger.info(f"Task ID: {task_id}")
    logger.info(f"ì…ë ¥ íŒŒë¼ë¯¸í„°:")
    logger.info(f"  - userId: {userId}")
    logger.info(f"  - trackId: {trackId}")
    logger.info(f"  - stemId: {stemId}")
    logger.info(f"  - filepath: {filepath}")
    logger.info(f"  - timestamp: {timestamp}")
    logger.info(f"  - sessionId: {sessionId}")
    logger.info(f"  - file_name: {file_name}")
    logger.info(f"  - category_id: {category_id}")
    logger.info("===========================================")
    
    try:
        # 1. ì„ì‹œ íŒŒì¼ ìƒì„±
        file_ext = os.path.splitext(filepath)[1] or '.wav'
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_ext) as tmp_file:
            local_filepath = tmp_file.name
        
        # 2. S3ì—ì„œ ì˜¤ë””ì˜¤ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        logger.info("S3ì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹œì‘: %s", filepath)
        if not aws_utils.download_from_s3(filepath, local_filepath):
            raise Exception("S3 íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
        
        # 3. íŒŒì¼ í•´ì‹œ ìƒì„±
        logger.info("íŒŒì¼ í•´ì‹œ ìƒì„± ì‹œì‘")
        audio_hash = generate_file_hash(local_filepath)
        logger.info(f"ìƒì„±ëœ í•´ì‹œ: {audio_hash}")
        
        # 4. ì›¹í›…ìœ¼ë¡œ í•´ì‹œ ì „ì†¡
        webhook_result = {
            'task_id': task_id,
            'userId': userId,
            'trackId': trackId,
            'stemId': stemId,
            'filepath': filepath,
            'audio_hash': audio_hash,
            'timestamp': timestamp,
            'original_filename': original_filename,
            'sessionId': sessionId,
            'file_name': file_name,
            'key': key,
            'tag': tag,
            'description': description,
            'category_id': category_id,
            'status': 'hash_generated'
        }
        
        logger.info("ì›¹í›… ì „ì†¡ ì‹œì‘")
        try:
            from .webhook import send_hash_webhook
            send_hash_webhook(stemId, webhook_result)
            logger.info("ì›¹í›… ì „ì†¡ ì™„ë£Œ")
        except Exception as e:
            logger.error("ì›¹í›… ì „ì†¡ ì‹¤íŒ¨: %s", e)
            raise
        
        # 5. ê²°ê³¼ ë°˜í™˜ (S3 íŒŒì¼ ê²½ë¡œë§Œ í¬í•¨, ì„ì‹œ íŒŒì¼ì€ ì œì™¸)
        result = {
            'task_id': task_id,
            'stemId': stemId,
            'audio_hash': audio_hash,
            'filepath': filepath,  # S3 íŒŒì¼ ê²½ë¡œë§Œ í¬í•¨
            'status': 'hash_sent_to_webhook',
            'processed_at': aws_utils._get_current_timestamp()
        }
        
        logger.info("í•´ì‹œ ìƒì„± ë° ì›¹í›… ì „ì†¡ ì™„ë£Œ: stemId=%s, hash=%s", stemId, audio_hash)
        return result
        
    except Exception as e:
        logger.error("í•´ì‹œ ìƒì„± ë° ì›¹í›… ì „ì†¡ ì‹¤íŒ¨: stemId=%s, error=%s", stemId, str(e))
        
        # ì¬ì‹œë„ ë¡œì§
        if self.request.retries < self.max_retries:
            logger.info("ì‘ì—… ì¬ì‹œë„ ì˜ˆì•½: stemId=%s, retry=%d/%d", 
                       stemId, self.request.retries + 1, self.max_retries)
            countdown = min(60 * (2 ** self.request.retries), 300)
            raise self.retry(exc=e, countdown=countdown)
        
        logger.error("ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼: stemId=%s", stemId)
        raise
        
    finally:
        # EC2 ì„ì‹œ íŒŒì¼ ì •ë¦¬ (ì„±ê³µ/ì‹¤íŒ¨ì™€ ê´€ê³„ì—†ì´ ì‹¤í–‰)
        if local_filepath and os.path.exists(local_filepath):
            try:
                os.unlink(local_filepath)
                logger.info("EC2 ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ: %s", local_filepath)
            except Exception as cleanup_error:
                logger.warning("EC2 ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: %s", cleanup_error)


@celery_app.task(name='app.tasks.process_duplicate_file', bind=True)
def process_duplicate_file(self, userId: str = None, trackId: str = None, 
                          stemId: str = None, filepath: str = None, 
                          audio_hash: str = None):
    """
    2ë‹¨ê³„: ì¤‘ë³µ íŒŒì¼ ì²˜ë¦¬ í…ŒìŠ¤í¬
    ì¤‘ë³µëœ í•´ì‹œê°’ì´ ìˆëŠ” ê²½ìš° S3ì—ì„œ íŒŒì¼ì„ ì‚­ì œ
    
    Args:
        userId: ì‚¬ìš©ì ID
        trackId: íŠ¸ë™ ID
        stemId: ìŠ¤í…œ ID
        filepath: S3 íŒŒì¼ ê²½ë¡œ
        audio_hash: ì˜¤ë””ì˜¤ í•´ì‹œê°’
        
    Returns:
        dict: ì²˜ë¦¬ ê²°ê³¼
    """
    task_id = self.request.id
    
    logger.info("====== ì¤‘ë³µ íŒŒì¼ ì²˜ë¦¬ í…ŒìŠ¤í¬ ì‹œì‘ ======")
    logger.info(f"Task ID: {task_id}")
    logger.info(f"ì…ë ¥ íŒŒë¼ë¯¸í„°:")
    logger.info(f"  - userId: {userId}")
    logger.info(f"  - trackId: {trackId}")
    logger.info(f"  - stemId: {stemId}")
    logger.info(f"  - filepath: {filepath}")
    logger.info(f"  - audio_hash: {audio_hash}")
    logger.info("====================================")
    
    try:
        # 1. S3ì—ì„œ ì¤‘ë³µ íŒŒì¼ ì‚­ì œ
        logger.info("S3ì—ì„œ ì¤‘ë³µ íŒŒì¼ ì‚­ì œ ì‹œì‘: %s", filepath)
        if not aws_utils.delete_from_s3(filepath):
            raise Exception("S3 íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨")
        
        # 2. ì²˜ë¦¬ ê²°ê³¼ ë°˜í™˜
        result = {
            'task_id': task_id,
            'stemId': stemId,
            'audio_hash': audio_hash,
            'filepath': filepath,
            'status': 'duplicate_file_deleted',
            'processed_at': aws_utils._get_current_timestamp()
        }
        
        # 3. ì›¹í›…ìœ¼ë¡œ ì™„ë£Œ ì•Œë¦¼ ì „ì†¡
        try:
            from .webhook import send_completion_webhook
            send_completion_webhook(stemId, result, "SUCCESS")
        except Exception as e:
            logger.warning("ì›¹í›… ì „ì†¡ ì‹¤íŒ¨: %s", e)
        
        logger.info("ì¤‘ë³µ íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ: stemId=%s", stemId)
        return result
        
    except Exception as e:
        logger.error("ì¤‘ë³µ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: stemId=%s, error=%s", stemId, str(e))
        
        # ì¬ì‹œë„ ë¡œì§
        if self.request.retries < self.max_retries:
            logger.info("ì‘ì—… ì¬ì‹œë„ ì˜ˆì•½: stemId=%s, retry=%d/%d", 
                       stemId, self.request.retries + 1, self.max_retries)
            countdown = min(60 * (2 ** self.request.retries), 300)
            raise self.retry(exc=e, countdown=countdown)
        
        logger.error("ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼: stemId=%s", stemId)
        raise


@celery_app.task(name='app.tasks.process_audio_analysis', bind=True)
def process_audio_analysis(self, userId: str = None, trackId: str = None, 
                          stemId: str = None, filepath: str = None, 
                          audio_hash: str = None, timestamp: str = None,
                          original_filename: str = None, num_peaks: int = None,
                          sessionId: str = None):
    """
    3ë‹¨ê³„: ì˜¤ë””ì˜¤ ë¶„ì„ í…ŒìŠ¤í¬
    ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ íŒŒí˜• ë°ì´í„°ë¥¼ ìƒì„±í•˜ê³  S3ì— ì €ì¥
    
    Args:
        userId: ì‚¬ìš©ì ID
        trackId: íŠ¸ë™ ID
        stemId: ìŠ¤í…œ ID
        filepath: S3 íŒŒì¼ ê²½ë¡œ
        audio_hash: ì˜¤ë””ì˜¤ í•´ì‹œê°’
        timestamp: íƒ€ì„ìŠ¤íƒ¬í”„
        original_filename: ì›ë³¸ íŒŒì¼ëª…
        num_peaks: ìƒì„±í•  íŒŒí˜• í”¼í¬ ê°œìˆ˜
        sessionId: ì„¸ì…˜ ID
        
    Returns:
        dict: ì²˜ë¦¬ ê²°ê³¼
    """
    task_id = self.request.id
    local_filepath = None
    waveform_filepath = None
    
    logger.info("====== ì˜¤ë””ì˜¤ ë¶„ì„ í…ŒìŠ¤í¬ ì‹œì‘ ======")
    logger.info(f"Task ID: {task_id}")
    logger.info(f"ì…ë ¥ íŒŒë¼ë¯¸í„°:")
    logger.info(f"  - userId: {userId}")
    logger.info(f"  - trackId: {trackId}")
    logger.info(f"  - stemId: {stemId}")
    logger.info(f"  - filepath: {filepath}")
    logger.info(f"  - audio_hash: {audio_hash}")
    logger.info(f"  - num_peaks: {num_peaks}")
    logger.info(f"  - sessionId: {sessionId}")
    logger.info("=================================")
    
    try:
        # 1. ì„ì‹œ íŒŒì¼ ìƒì„±
        file_ext = os.path.splitext(filepath)[1] or '.wav'
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_ext) as tmp_file:
            local_filepath = tmp_file.name
        
        # 2. S3ì—ì„œ ì˜¤ë””ì˜¤ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        logger.info("S3ì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹œì‘: %s", filepath)
        if not aws_utils.download_from_s3(filepath, local_filepath):
            raise Exception("S3 íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
        
        # 3. ì˜¤ë””ì˜¤ íŒŒì¼ ë¶„ì„
        logger.info("ì˜¤ë””ì˜¤ íŒŒì¼ ë¶„ì„ ì‹œì‘")
        processor = AudioProcessor(local_filepath)
        
        # ëª¨ë“  ë¶„ì„ ê³¼ì • ì‹¤í–‰
        result = processor.process_all(num_peaks)
        
        # 4. íŒŒí˜• ë°ì´í„°ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        waveform_filename = f"{stemId}_waveform_{uuid.uuid4().hex[:8]}.json"
        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.json') as tmp_waveform:
            waveform_filepath = tmp_waveform.name
            tmp_waveform.write(processor.generate_waveform_json(num_peaks))
        
        # 5. íŒŒí˜• ë°ì´í„°ë¥¼ S3ì— ì—…ë¡œë“œ
        waveform_s3_path = f"waveforms/{waveform_filename}"
        logger.info("íŒŒí˜• ë°ì´í„° S3 ì—…ë¡œë“œ ì‹œì‘: %s", waveform_s3_path)
        
        if not aws_utils.upload_to_s3(waveform_filepath, waveform_s3_path):
            raise Exception("íŒŒí˜• ë°ì´í„° S3 ì—…ë¡œë“œ ì‹¤íŒ¨")
        
        # 6. ì²˜ë¦¬ ê²°ê³¼ ë°˜í™˜
        final_result = {
            'task_id': task_id,
            'stemId': stemId,
            'status': 'success',
            'audio_data_hash': audio_hash,
            'waveform_data_path': waveform_s3_path,
            'file_size': result['file_size'],
            'duration': result['duration'],
            'sample_rate': result['sample_rate'],
            'num_peaks': result['num_peaks'],
            'mime_type': result['mime_type'],
            'processed_at': result['processed_at']
        }
        
        # 7. ì›¹ì„œë²„ë¡œ ì™„ë£Œ ì•Œë¦¼ ì „ì†¡
        try:
            from .webhook import send_completion_webhook
            send_completion_webhook(stemId, final_result, "SUCCESS")
        except Exception as e:
            logger.warning("ì›¹í›… ì „ì†¡ ì‹¤íŒ¨: %s", e)
        
        logger.info("ì˜¤ë””ì˜¤ ë¶„ì„ ì™„ë£Œ: stemId=%s", stemId)
        return final_result
        
    except Exception as e:
        logger.error("ì˜¤ë””ì˜¤ ë¶„ì„ ì‹¤íŒ¨: stemId=%s, error=%s", stemId, str(e))
        
        # ì›¹í›…ìœ¼ë¡œ ì—ëŸ¬ ì „ì†¡
        try:
            from .webhook import send_completion_webhook
            error_result = {
                'stemId': stemId,
                'error_message': str(e),
                'error_code': type(e).__name__,
                'timestamp': aws_utils._get_current_timestamp()
            }
            send_completion_webhook(stemId, error_result, "FAILURE")
        except Exception as webhook_error:
            logger.warning("ì›¹í›… ì—ëŸ¬ ì „ì†¡ ì‹¤íŒ¨: %s", webhook_error)
        
        # ì¬ì‹œë„ ë¡œì§
        if self.request.retries < self.max_retries:
            logger.info("ì‘ì—… ì¬ì‹œë„ ì˜ˆì•½: stemId=%s, retry=%d/%d", 
                       stemId, self.request.retries + 1, self.max_retries)
            countdown = min(60 * (2 ** self.request.retries), 300)
            raise self.retry(exc=e, countdown=countdown)
        
        logger.error("ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼: stemId=%s", stemId)
        raise
        
    finally:
        # âš ï¸ ì¤‘ìš”: S3 ì›ë³¸ íŒŒì¼ì€ ì ˆëŒ€ ì‚­ì œí•˜ì§€ ì•ŠìŒ!
        # EC2 ë‚´ì˜ ì„ì‹œ íŒŒì¼ë“¤ë§Œ ì •ë¦¬
        
        # 1. ë¡œì»¬ ì„ì‹œ ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë¦¬
        try:
            if local_filepath and os.path.exists(local_filepath):
                os.unlink(local_filepath)
                logger.info("EC2 ì„ì‹œ ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ: %s", local_filepath)
        except Exception as e:
            logger.warning("EC2 ì„ì‹œ ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: %s", e)
        
        # 2. ë¡œì»¬ ì„ì‹œ íŒŒí˜• íŒŒì¼ ì •ë¦¬
        try:
            if waveform_filepath and os.path.exists(waveform_filepath):
                os.unlink(waveform_filepath)
                logger.info("EC2 ì„ì‹œ íŒŒí˜• íŒŒì¼ ì •ë¦¬ ì™„ë£Œ: %s", waveform_filepath)
        except Exception as e:
            logger.warning("EC2 ì„ì‹œ íŒŒí˜• íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: %s", e)
        
        # 3. ì¶”ê°€ ì„ì‹œ íŒŒì¼ ì •ë¦¬ (AudioProcessorì—ì„œ ìƒì„±ë  ìˆ˜ ìˆëŠ” íŒŒì¼ë“¤)
        try:
            import glob
            temp_dir = tempfile.gettempdir()
            
            # stemIdê°€ Noneì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ íŒ¨í„´ ê²€ìƒ‰
            if stemId:
                temp_pattern = f"tmp*{stemId}*"
                for temp_file in glob.glob(os.path.join(temp_dir, temp_pattern)):
                    if os.path.exists(temp_file):
                        os.unlink(temp_file)
                        logger.debug("ì¶”ê°€ ì„ì‹œ íŒŒì¼ ì •ë¦¬: %s", temp_file)
            else:
                logger.debug("stemIdê°€ Noneì´ë¯€ë¡œ íŒ¨í„´ ê¸°ë°˜ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ê±´ë„ˆëœ€")
        except Exception as e:
            logger.warning("ì¶”ê°€ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: %s", e)
        
        # ğŸ“ ì°¸ê³ : S3 ì›ë³¸ íŒŒì¼ (filepath)ì€ ë³´ì¡´ë¨
        logger.info("S3 ì›ë³¸ íŒŒì¼ ë³´ì¡´ë¨: %s", filepath)


def generate_file_hash(filepath: str) -> str:
    """
    íŒŒì¼ì˜ í•´ì‹œê°’ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        filepath: íŒŒì¼ ê²½ë¡œ
        
    Returns:
        str: SHA-256 í•´ì‹œê°’
    """
    hash_sha256 = hashlib.sha256()
    
    with open(filepath, "rb") as f:
        # í° íŒŒì¼ì„ ìœ„í•´ ì²­í¬ ë‹¨ìœ„ë¡œ ì½ê¸°
        for chunk in iter(lambda: f.read(4096), b""):
            hash_sha256.update(chunk)
    
    return hash_sha256.hexdigest()


# ê¸°ì¡´ í…ŒìŠ¤í¬ë“¤ (í˜¸í™˜ì„± ìœ ì§€)
@celery_app.task(name='health_check', bind=True)
def health_check(self):
    """
    ì›Œì»¤ ìƒíƒœ í™•ì¸ì„ ìœ„í•œ í—¬ìŠ¤ ì²´í¬ íƒœìŠ¤í¬
    
    Returns:
        dict: ì›Œì»¤ ìƒíƒœ ì •ë³´
    """
    try:
        logger.info("í—¬ìŠ¤ ì²´í¬ ì‹¤í–‰: task_id=%s", self.request.id)
        
        # ê¸°ë³¸ ìƒíƒœ ì •ë³´
        status = {
            'status': 'healthy',
            'task_id': self.request.id,
            'worker_id': self.request.hostname,
            'timestamp': aws_utils._get_current_timestamp()
        }
        
        # AWS ì„œë¹„ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸
        try:
            # S3 ì—°ê²° í…ŒìŠ¤íŠ¸ (ë²„í‚· ì¡´ì¬ í™•ì¸)
            aws_utils.s3_client.head_bucket(Bucket=aws_utils.config.S3_BUCKET_NAME)
            status['s3_connection'] = 'ok'
        except Exception as e:
            status['s3_connection'] = f'error: {str(e)}'
        
        try:
            # SQS ì—°ê²° í…ŒìŠ¤íŠ¸ (ì‘ì—… í ì†ì„± í™•ì¸)
            aws_utils.sqs_client.get_queue_attributes(
                QueueUrl=aws_utils.config.SQS_QUEUE_URL,
                AttributeNames=['QueueArn']
            )
            status['sqs_connection'] = 'ok'
        except Exception as e:
            status['sqs_connection'] = f'error: {str(e)}'
        
        logger.info("í—¬ìŠ¤ ì²´í¬ ì™„ë£Œ: %s", status)
        return status
        
    except Exception as e:
        logger.error("í—¬ìŠ¤ ì²´í¬ ì‹¤íŒ¨: %s", e)
        return {
            'status': 'unhealthy',
            'error': str(e),
            'timestamp': aws_utils._get_current_timestamp()
        }


@celery_app.task(name='cleanup_temp_files', bind=True)
def cleanup_temp_files(self):
    """
    EC2 ì„ì‹œ íŒŒì¼ ì •ë¦¬ íƒœìŠ¤í¬
    ì˜¤ë””ì˜¤ ì²˜ë¦¬ ê³¼ì •ì—ì„œ ìƒì„±ëœ ì„ì‹œ íŒŒì¼ë“¤ì„ ì •ë¦¬í•©ë‹ˆë‹¤.
    
    Returns:
        dict: ì •ë¦¬ ê²°ê³¼
    """
    try:
        logger.info("EC2 ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹œì‘: task_id=%s", self.request.id)
        
        temp_dir = tempfile.gettempdir()
        cleaned_count = 0
        error_count = 0
        total_size_cleaned = 0
        
        # ì„ì‹œ ë””ë ‰í† ë¦¬ì—ì„œ ì˜¤ë˜ëœ íŒŒì¼ ì°¾ê¸°
        import time
        current_time = time.time()
        max_age = 1800  # 30ë¶„ (ì˜¤ë””ì˜¤ ì²˜ë¦¬ í›„ ì¶©ë¶„í•œ ì‹œê°„)
        
        # ì˜¤ë””ì˜¤ ì²˜ë¦¬ ê´€ë ¨ ì„ì‹œ íŒŒì¼ íŒ¨í„´ë“¤
        audio_extensions = ['.wav', '.mp3', '.flac', '.ogg', '.m4a', '.aac']
        temp_patterns = [
            'tmp',          # tempfile ëª¨ë“ˆ ê¸°ë³¸ prefix
            'audio_',       # ì˜¤ë””ì˜¤ ê´€ë ¨ ì„ì‹œ íŒŒì¼
            'waveform_',    # íŒŒí˜• ê´€ë ¨ ì„ì‹œ íŒŒì¼
            'stem'          # stem ê´€ë ¨ ì„ì‹œ íŒŒì¼
        ]
        
        for filename in os.listdir(temp_dir):
            filepath = os.path.join(temp_dir, filename)
            
            # íŒŒì¼ì¸ì§€ í™•ì¸
            if not os.path.isfile(filepath):
                continue
            
            # ìš°ë¦¬ê°€ ìƒì„±í•œ ì„ì‹œ íŒŒì¼ì¸ì§€ í™•ì¸
            is_our_temp_file = False
            
            # íŒ¨í„´ ê¸°ë°˜ í™•ì¸
            for pattern in temp_patterns:
                if filename.startswith(pattern):
                    is_our_temp_file = True
                    break
            
            # í™•ì¥ì ê¸°ë°˜ í™•ì¸ (ì˜¤ë””ì˜¤ íŒŒì¼)
            if not is_our_temp_file:
                for ext in audio_extensions:
                    if filename.endswith(ext) and (filename.startswith('tmp') or 'temp' in filename.lower()):
                        is_our_temp_file = True
                        break
            
            # JSON íŒŒí˜• íŒŒì¼ í™•ì¸
            if not is_our_temp_file and filename.endswith('.json'):
                if any(keyword in filename for keyword in ['waveform', 'peaks', 'audio']):
                    is_our_temp_file = True
            
            if not is_our_temp_file:
                continue
            
            try:
                # íŒŒì¼ ë‚˜ì´ í™•ì¸
                file_age = current_time - os.path.getmtime(filepath)
                if file_age > max_age:
                    # íŒŒì¼ í¬ê¸° ê¸°ë¡
                    file_size = os.path.getsize(filepath)
                    
                    # íŒŒì¼ ì‚­ì œ
                    os.unlink(filepath)
                    cleaned_count += 1
                    total_size_cleaned += file_size
                    
                    logger.debug("ì„ì‹œ íŒŒì¼ ì •ë¦¬: %s (í¬ê¸°: %d bytes, ë‚˜ì´: %.1fë¶„)", 
                               filepath, file_size, file_age / 60)
                    
            except Exception as e:
                error_count += 1
                logger.warning("ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: %s, error: %s", filepath, e)
        
        # ì¶”ê°€: ë§¤ìš° ì˜¤ë˜ëœ íŒŒì¼ë“¤ ê°•ì œ ì •ë¦¬ (2ì‹œê°„ ì´ìƒ)
        very_old_age = 7200  # 2ì‹œê°„
        very_old_cleaned = 0
        
        try:
            import glob
            # ë§¤ìš° ì˜¤ë˜ëœ ì„ì‹œ íŒŒì¼ë“¤ ì°¾ê¸°
            for pattern in ['tmp*', 'audio_*', 'waveform_*']:
                for filepath in glob.glob(os.path.join(temp_dir, pattern)):
                    if os.path.isfile(filepath):
                        file_age = current_time - os.path.getmtime(filepath)
                        if file_age > very_old_age:
                            try:
                                file_size = os.path.getsize(filepath)
                                os.unlink(filepath)
                                very_old_cleaned += 1
                                total_size_cleaned += file_size
                                logger.info("ë§¤ìš° ì˜¤ë˜ëœ ì„ì‹œ íŒŒì¼ ê°•ì œ ì •ë¦¬: %s", filepath)
                            except Exception:
                                pass
        except Exception as e:
            logger.warning("ë§¤ìš° ì˜¤ë˜ëœ íŒŒì¼ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: %s", e)
        
        result = {
            'status': 'completed',
            'cleaned_count': cleaned_count + very_old_cleaned,
            'error_count': error_count,
            'total_size_cleaned_bytes': total_size_cleaned,
            'total_size_cleaned_mb': round(total_size_cleaned / (1024 * 1024), 2),
            'max_age_minutes': max_age / 60,
            'temp_directory': temp_dir,
            'timestamp': aws_utils._get_current_timestamp()
        }
        
        logger.info("EC2 ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ: %dê°œ íŒŒì¼ ì •ë¦¬ (%.2f MB)", 
                   result['cleaned_count'], result['total_size_cleaned_mb'])
        return result
        
    except Exception as e:
        logger.error("EC2 ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: %s", e)
        return {
            'status': 'error',
            'error': str(e),
            'timestamp': aws_utils._get_current_timestamp()
        } 